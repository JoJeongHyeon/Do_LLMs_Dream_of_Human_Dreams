# 🧠 Dive into LLaMA's Brain: 문맥 속 단어 의미 분화의 AI적 이해

## 🧭 프로젝트 개요

이 프로젝트는 LLaMA 언어 모델이 문맥에 따라 **특정 단어의 의미를 어떻게 다르게 처리하는지**를 분석하고 시각화한 실험입니다.  
실험 데이터는 '모두의 말뭉치' 중 **구어체**와 **신문체**에서 수집된 실제 문장을 기반으로 하며,  
같은 단어라도 문맥에 따라 **내부 토큰 가중치**가 어떻게 변화하는지를 추적합니다.

---

## 🔍 핵심 질문

- LLaMA 모델은 **동음이의어**(예: "은행")나 **의미 분기 단어**를 어떻게 해석하는가?
- 동일 단어가 등장할 때, 문맥에 따라 Attention 가중치는 어떻게 달라지는가?
- 언어 모델이 '의미 분화'를 할 수 있다면, 이는 인간처럼 단어 의미를 이해한다는 근거가 될 수 있을까?

---

## 🧪 실험 구성

### 1. `check_corpus.ipynb`
- 🔹 사용 말뭉치: [모두의 말뭉치](https://corpus.korean.go.kr)
- 🔹 대상 데이터: 구어체, 신문체
- 🔹 주요 기능: 타겟 단어가 포함된 다양한 문장을 자동 수집 및 정제

### 2. `Dive_into_Llama_brain.ipynb`
- 🔹 모델: `LLaMA` (Meta AI)
- 🔹 접근 방식:
  - 각 문장에서 **타겟 단어의 토큰 ID 추출**
  - Attention 가중치, Hidden State 등 시각화
  - 문맥마다 달라지는 벡터 거리 및 군집 패턴 분석
- 🔹 출력 결과:
  - 각 단어의 의미 변화 흐름을 시각적 이미지로 표현

---

## 🖼️ 시각화 결과 예시

아래는 타겟 단어의 문맥별 처리 차이를 시각화한 일부 결과입니다:

### 🟠 예시: `은행` (금융기관 vs 강둑)

- `1-동음이의구분.png`: **같은 단어**가 문맥에 따라 **벡터 군집이 달라지는 것**을 확인

> 추가 이미지 파일:  
> `2-문맥차이1.png`, `3-문맥차이2.png`, `4-문맥차이3.png` 등

---

## 🛠️ 사용 기술 및 도구

| 구분 | 내용 |
|------|------|
| 언어 | Python |
| 모델 | LLaMA |
| 분석 | HuggingFace Transformers, NumPy, Matplotlib |
| 데이터 | 모두의 말뭉치 (구어/신문 말뭉치) |
| 시각화 | Matplotlib, Token별 가중치 색상 처리 |

---

## 🔮 향후 연구 방향

- BERT, GPT 등 다른 모델과의 비교 실험 진행
